{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "basic-assumption",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set(\"paper\", \"white\")\n",
    "from pyns import Neuroscout\n",
    "import math\n",
    "\n",
    "api = Neuroscout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "vertical-pontiac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset count = 12\n",
      "\n",
      "Dataset Name, ID, n_tasks, n_runs:\n",
      "\n",
      "Budapest 27 1 5\n",
      "HealthyBrainNetwork 8 1 1\n",
      "SchematicNarrative 20 1 4\n",
      "studyforrest 11 1 8\n",
      "Raiders 10 1 8\n",
      "Life 9 1 4\n",
      "ParanoiaStory 18 1 3\n",
      "Sherlock 21 1 1\n",
      "SherlockMerlin 5 2 1\n",
      "LearningTemporalStructure 19 1 3\n",
      "ReadingBrainProject 29 1 5\n",
      "NaturalisticNeuroimagingDatabase 28 10 1\n"
     ]
    }
   ],
   "source": [
    "datasets = api.datasets.get()\n",
    "print(f'dataset count = {len(api.datasets.get())}\\n')\n",
    "print('Dataset Name, ID, n_tasks, n_runs:\\n')\n",
    "dataset_ids = []\n",
    "dataset_names = []\n",
    "dataset_n_runs = []\n",
    "dataset_tasks = []\n",
    "for i in datasets:\n",
    "    dataset_ids.append(i['id'])\n",
    "    dataset_names.append(i['name'])\n",
    "    dataset_tasks.append(len(i['tasks']))\n",
    "    dataset_n_runs.append(i['tasks'][0]['n_runs_subject'])\n",
    "    print(i['name'], i['id'], len(i['tasks']), i['tasks'][0]['n_runs_subject'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "nutritional-piano",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 10]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aggressive-function",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictors(run_id):\n",
    "    # input: a neuroscout run_id \n",
    "    # outputs:\n",
    "    # - a pandas dataframe of predictors\n",
    "    # - list of ids\n",
    "    # - list of names\n",
    "    # - list of modality\n",
    "    predictors=api.predictors.get(run_id=run_id)\n",
    "    predictor_ids = []\n",
    "    predictor_names = []\n",
    "    predictor_modality = []\n",
    "    for i in predictors:\n",
    "        if not i['source'] == 'fmriprep' and not i['mean'] == None and str(i['name']).find(\"bert\") < 0:\n",
    "            predictor_ids.append(i['id'])\n",
    "            predictor_names.append(i['name'])\n",
    "            try:\n",
    "                predictor_modality.append(i['extracted_feature']['modality'])\n",
    "            except:\n",
    "                predictor_modality.append(None)\n",
    "                \n",
    "    df_predictors=pd.DataFrame(data= np.array([predictor_ids,predictor_modality,predictor_names]).T , columns=['id','modality','names'])\n",
    "    df_predictors = df_predictors.sort_values(by=['id','names','modality'])\n",
    "    predictor_ids= df_predictors['id'].to_numpy()\n",
    "    predictor_names= df_predictors['names'].to_numpy()\n",
    "    predictor_modality= df_predictors['modality'].to_numpy()\n",
    "\n",
    "\n",
    "\n",
    "    return(df_predictors, predictor_ids, predictor_names, predictor_modality)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parallel-routine",
   "metadata": {},
   "source": [
    "## which predictors are common to all av clips? (except NND)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "agreed-floor",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset_ids = [27,28,8,20,11,10,9,21,5]\n",
    "#dataset_names = ['Budapest','NaturalisticNeuroimagingDatabase','HealthyBrainNetwork','SchematicNarrative','studyforrest','Raiders','Life','Sherlock','SherlockMerlin']\n",
    "dataset_ids = [27,8,20,11,10,9,21,5]\n",
    "dataset_names = ['Budapest','HealthyBrainNetwork','SchematicNarrative','studyforrest','Raiders','Life','Sherlock','SherlockMerlin']\n",
    "dataset_tasks = [1, 1, 1, 1, 1, 1, 1, 2]\n",
    "dataset_n_runs = [5, 1, 4, 8, 8, 4, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "further-prime",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_list_list = []\n",
    "predictor_names_list = []\n",
    "for i,d in enumerate(dataset_ids):\n",
    "    subject = api.runs.get(dataset_id=d)[0]['subject']\n",
    "    #print(subject)\n",
    "    run_id=api.runs.get(dataset_id=d, subject=subject)[0]['id']\n",
    "    #print(run_id)\n",
    "    run_duration=api.runs.get(dataset_id=d, subject=subject)[0]['duration']\n",
    "    \n",
    "    df_predictors, predictor_ids, predictor_names, predictor_modality = get_predictors(run_id)\n",
    "    predictor_list_list.append(predictor_ids)\n",
    "    predictor_names_list.append(predictor_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "active-twist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['abstract', 'action', 'alphabet', 'animal', 'architecture', 'art',\n",
       "       'as-Alarm', 'as-Animal', 'as-Engine', 'as-Explosion', 'as-Fire',\n",
       "       'as-Glass', 'as-Hands', 'as-Liquid', 'as-Mechanisms', 'as-Music',\n",
       "       'as-Musical instrument', 'as-Noise', 'as-Silence', 'as-Speech',\n",
       "       'as-Thunderstorm', 'as-Tools', 'as-Vehicle', 'as-Water',\n",
       "       'as-Whistling', 'as-Wild animals', 'as-Wind', 'as-Wood', 'blur',\n",
       "       'brightness', 'building', 'business', 'car', 'child',\n",
       "       'chroma_cqt_0', 'chroma_cqt_1', 'chroma_cqt_10', 'chroma_cqt_11',\n",
       "       'chroma_cqt_2', 'chroma_cqt_3', 'chroma_cqt_4', 'chroma_cqt_5',\n",
       "       'chroma_cqt_6', 'chroma_cqt_7', 'chroma_cqt_8', 'chroma_cqt_9',\n",
       "       'city', 'color', 'competition', 'creativity', 'dark', 'daylight',\n",
       "       'design', 'desktop', 'empty', 'equipment', 'face', 'family',\n",
       "       'fashion', 'furniture', 'girl', 'hand', 'home', 'horizontal',\n",
       "       'illustration', 'image', 'indoors', 'landscape', 'light', 'man',\n",
       "       'mel_0', 'mel_1', 'mel_10', 'mel_11', 'mel_12', 'mel_13', 'mel_14',\n",
       "       'mel_15', 'mel_16', 'mel_17', 'mel_18', 'mel_19', 'mel_2',\n",
       "       'mel_20', 'mel_21', 'mel_22', 'mel_23', 'mel_24', 'mel_25',\n",
       "       'mel_26', 'mel_27', 'mel_28', 'mel_29', 'mel_3', 'mel_30',\n",
       "       'mel_31', 'mel_32', 'mel_33', 'mel_34', 'mel_35', 'mel_36',\n",
       "       'mel_37', 'mel_38', 'mel_39', 'mel_4', 'mel_40', 'mel_41',\n",
       "       'mel_42', 'mel_43', 'mel_44', 'mel_45', 'mel_46', 'mel_47',\n",
       "       'mel_5', 'mel_6', 'mel_7', 'mel_8', 'mel_9', 'mfcc_0', 'mfcc_1',\n",
       "       'mfcc_10', 'mfcc_11', 'mfcc_12', 'mfcc_13', 'mfcc_14', 'mfcc_15',\n",
       "       'mfcc_16', 'mfcc_17', 'mfcc_18', 'mfcc_19', 'mfcc_2', 'mfcc_3',\n",
       "       'mfcc_4', 'mfcc_5', 'mfcc_6', 'mfcc_7', 'mfcc_8', 'mfcc_9',\n",
       "       'military', 'music', 'nature', 'old', 'one', 'outdoors', 'pattern',\n",
       "       'people', 'portrait', 'recreation', 'retro', 'rms', 'road', 'room',\n",
       "       'sharpness', 'shot_change', 'simplicity', 'sky',\n",
       "       'spectral_centroid', 'street', 'summer', 'sunset', 'technology',\n",
       "       'text', 'tonal_centroid_0', 'tonal_centroid_1', 'tonal_centroid_2',\n",
       "       'tonal_centroid_3', 'tonal_centroid_4', 'tonal_centroid_5', 'tool',\n",
       "       'travel', 'two', 'vehicle', 'vertical', 'vibrance', 'water',\n",
       "       'wear', 'wild', 'wildlife', 'woman', 'wood', 'writing'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor_names_intersect = predictor_names_list[0].copy()\n",
    "\n",
    "for i in predictor_names_list[1:]:\n",
    "    predictor_names_intersect = np.intersect1d(predictor_names_intersect,i)\n",
    "   # print(predictor_names_intersect)\n",
    "predictor_names_intersect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "muslim-assumption",
   "metadata": {},
   "source": [
    "## get these features from all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "returning-taiwan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api.datasets.get(8)['tasks'][0]['id']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "sacred-cleveland",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t=1\n",
    "datasets[8]['tasks'][t]['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "southern-closing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budapest 1\n",
      "Budapest 0 1\n",
      "Budapest 2\n",
      "Budapest 0 2\n",
      "Budapest 3\n",
      "Budapest 0 3\n",
      "Budapest 4\n",
      "Budapest 0 4\n",
      "Budapest 5\n",
      "Budapest 0 5\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-128-d560472030de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mrun_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mruns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubject\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubject\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtask_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtask_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0mrun_duration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mruns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubject\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'duration'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "for i,ds_id in enumerate(dataset_ids):\n",
    "    ds_name = dataset_names[i]\n",
    "    ds_n_runs = dataset_n_runs[i]\n",
    "    ds_n_tasks = dataset_tasks[i]\n",
    "    subject = api.runs.get(dataset_id = dataset_ids[0])[0]['subject']\n",
    "    \n",
    "    #loop through tasks (eg sherlock merlin)\n",
    "    #if ds_n_tasks > 1:\n",
    "    for t in np.arange(ds_n_tasks):\n",
    "        task_id = api.datasets.get(ds_id)['tasks'][t]['id']\n",
    "\n",
    "        #loop through runs (eg budapest)\n",
    "        if ds_n_runs>1:\n",
    "            for n in np.arange(1,ds_n_runs+1):    \n",
    "                print(ds_name,n)\n",
    "                run_id=api.runs.get(dataset_id=ds_id, subject=subject,task_id=task_id,number=n)[0]['id']\n",
    "                run_duration=api.runs.get(dataset_id=ds_id, subject=subject,number=n)[0]['duration']\n",
    "                print(ds_name,t,n)\n",
    "        else:\n",
    "            run_id=api.runs.get(dataset_id=ds_id, subject=subject,task_id=task_id)[0]['id']\n",
    "            run_duration=api.runs.get(dataset_id=ds_id, subject=subject)[0]['duration']\n",
    "            print(ds_name,t,0)\n",
    "\n",
    "#     #\n",
    "#     else:\n",
    "#         runs = api.runs.get(dataset_id=ds_id, subject=subject)\n",
    "\n",
    "        \n",
    "        \n",
    "#         task_list = []\n",
    "#         task_names = []\n",
    "#         run_ids = []\n",
    "#         for r in runs:\n",
    "#             task_list.append(r['task'])\n",
    "#             task_names.append(r['task_name'])\n",
    "#             run_ids.append(r['id'])\n",
    "#         task_list,ind = np.unique(np.asarray(task_list),return_index=True)\n",
    "\n",
    "#         task_name_list = []\n",
    "#         run_id_list = []\n",
    "#         for i in ind:\n",
    "#             task_name_list.append(task_names[i])\n",
    "#             run_id_list.append(run_ids[i])\n",
    "#         print(task_list)\n",
    "#         print(task_name_list)\n",
    "#         print(run_id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indian-commodity",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_feats = []\n",
    "for number in np.arange(5):\n",
    "    number+=1\n",
    "    run_id=api.runs.get(dataset_id=27, subject=subject,number=number)[0]['id']\n",
    "    run_duration=api.runs.get(dataset_id=27, subject=subject,number=number)[0]['duration']\n",
    "    df_predictors, predictor_ids, predictor_names, predictor_modality = get_predictors(run_id)\n",
    "    feats = get_timeseries(predictor_ids,run_id,run_duration)\n",
    "    all_feats.append(feats)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
