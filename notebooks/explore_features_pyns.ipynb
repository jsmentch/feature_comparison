{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "domestic-productivity",
   "metadata": {},
   "source": [
    "# notebook to explore extracted movie features from neuroscout with pyns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "demanding-english",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "racial-money",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyns import Neuroscout\n",
    "api = Neuroscout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "floral-hygiene",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#there are 12 datasets\n",
    "len(api.datasets.get())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "raised-athens",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budapest 27\n",
      "NaturalisticNeuroimagingDatabase 28\n",
      "HealthyBrainNetwork 8\n",
      "SchematicNarrative 20\n",
      "studyforrest 11\n",
      "Raiders 10\n",
      "Life 9\n",
      "ParanoiaStory 18\n",
      "Sherlock 21\n",
      "SherlockMerlin 5\n",
      "LearningTemporalStructure 19\n",
      "ReadingBrainProject 29\n"
     ]
    }
   ],
   "source": [
    "datasets = api.datasets.get()\n",
    "for i in datasets:\n",
    "    print(i['name'], i['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "liquid-colon",
   "metadata": {},
   "outputs": [],
   "source": [
    "budapest = datasets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "liable-foundation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'TR': 1.0,\n",
       "  'avg_run_duration': 610,\n",
       "  'id': 48,\n",
       "  'n_runs_subject': 5,\n",
       "  'n_subjects': 25,\n",
       "  'name': 'movie',\n",
       "  'summary': 'Movie watching'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "budapest['tasks']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "precious-daisy",
   "metadata": {},
   "source": [
    "### let's just look at budapest to start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "domestic-reliance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'acquisition': None,\n",
       "  'dataset_id': 27,\n",
       "  'duration': 598.0,\n",
       "  'id': 1433,\n",
       "  'number': 1,\n",
       "  'session': None,\n",
       "  'subject': 'sid000005',\n",
       "  'task': 48,\n",
       "  'task_name': 'movie'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api.runs.get(dataset_id=27, subject='sid000005',number=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "straight-guess",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the run number for just BUDAPEST, SUBJECT5, PART1\n",
    "run_id=api.runs.get(dataset_id=27, subject='sid000005',number=1)[0]['id']\n",
    "run_duration=api.runs.get(dataset_id=27, subject='sid000005',number=1)[0]['duration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "under-drive",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "metropolitan-fields",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-8-2d0fea57a0a6>, line 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-8-2d0fea57a0a6>\"\u001b[0;36m, line \u001b[0;32m10\u001b[0m\n\u001b[0;31m    'source': 'fmriprep'},\u001b[0m\n\u001b[0m                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "[{'dataset_id': 27,\n",
    "  'description': 'Average signal in CSF mask',\n",
    "  'id': 37048,\n",
    "  'max': 437.444,\n",
    "  'mean': 369.345,\n",
    "  'min': 287.63,\n",
    "  'name': 'csf',\n",
    "  'num_na': 0,\n",
    "  'private': False,\n",
    "  'source': 'fmriprep'},"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "monetary-vaccine",
   "metadata": {},
   "source": [
    "### get just the non-fmriprep predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "prescribed-miller",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subtlexusfrequency_FREQcount Number of times the word appears in the corpus\n",
      "subtlexusfrequency_FREQlow The number of times the word appears in the corpus starting with a lowercase letter\n",
      "subtlexusfrequency_SUBTLWF The word frequency per million words\n",
      "subtlexusfrequency_SUBTLCD Indicates in what percent of the films the word appears\n",
      "subtlexusfrequency_Dom_PoS_SUBTLEX The dominant (most frequent) part of speech of each entry\n",
      "subtlexusfrequency_Percentage_dom_PoS The relative frequency of the dominant part of speech\n",
      "subtlexusfrequency_All_freqs_SUBTLEX The frequencies of each part of speech\n",
      "affect_V.Mean.Sum Mean valence of spoken words.\n",
      "affect_D.Mean.Sum Mean dominance of spoken words.\n",
      "aoa_AoA_Kup Age of aquisition of spoken words.\n",
      "massiveauditorylexicaldecision_NumPhones The number of phones in the item.\n",
      "massiveauditorylexicaldecision_FreqCOCAspok Word frequency in the COCA corpus.spok\n",
      "lancastersensorimotornorms_Auditory.mean how strongly the spoken word is experienced by hearing\n",
      "lancastersensorimotornorms_Haptic.mean how strongly the spoken word is experienced by feeling through touch\n",
      "lancastersensorimotornorms_Olfactory.mean how strongly the spoken word is experienced by smelling\n",
      "lancastersensorimotornorms_Foot_leg.mean how strongly the spoken word is experienced by performing an action with the foot / leg\n",
      "lancastersensorimotornorms_Head.mean how strongly the spoken word is experienced by performing an action with the head excluding mouth\n",
      "lancastersensorimotornorms_Torso.mean how strongly the spoken word is experienced by performing an action with the torso\n",
      "subtlexusfrequency_CDcount The number of films in which the word appears\n",
      "subtlexusfrequency_Cdlow The number of films in which the word appears starting with a lowercase letter\n",
      "subtlexusfrequency_Lg10WF This value is based on log10(FREQcount+1)\n",
      "subtlexusfrequency_Lg10CD This value is based on log10(CDcount+1)\n",
      "subtlexusfrequency_Freq_dom_PoS_SUBTLEX The frequency of the dominant part of speech\n",
      "subtlexusfrequency_All_PoS_SUBTLEX All parts of speech observed for the entry\n",
      "subtlexusfrequency_Zipf-value Zipf frequency\n",
      "affect_A.Mean.Sum Mean arousal of spoken words.\n",
      "concreteness_Conc.M Mean concreteness rating of spoken words.\n",
      "massiveauditorylexicaldecision_NumSylls The number of syllables in the item.\n",
      "massiveauditorylexicaldecision_Duration The duration of the item in milliseconds.\n",
      "massiveauditorylexicaldecision_PhonLev Mean phone-level Levenshtein distance from all entries in CMU-A.\n",
      "lancastersensorimotornorms_Gustatory.mean how strongly the spoken word is experienced by tasting\n",
      "lancastersensorimotornorms_Interoceptive.mean how strongly the spoken word is experienced by sensations inside the body\n",
      "lancastersensorimotornorms_Visual.mean how strongly the spoken word is experienced by seeing\n",
      "lancastersensorimotornorms_Hand_arm.mean how strongly the spoken word is experienced by performing an action with the hand / arm\n",
      "lancastersensorimotornorms_Mouth.mean how strongly the spoken word is experienced by performing an action with the mouth / throat\n",
      "BERTLM_pre_25_surprisal BERTLM_pre_25 surprisal (-log(masked_prediction))\n",
      "mel_10 Melspectrogram bin 10\n",
      "abstract Clarifai image recognition label: abstract\n",
      "action Clarifai image recognition label: action\n",
      "adult Clarifai image recognition label: adult\n",
      "animal Clarifai image recognition label: animal\n",
      "architecture Clarifai image recognition label: architecture\n",
      "art Clarifai image recognition label: art\n",
      "blur Clarifai image recognition label: blur\n",
      "business Clarifai image recognition label: business\n",
      "car Clarifai image recognition label: car\n",
      "child Clarifai image recognition label: child\n",
      "city Clarifai image recognition label: city\n",
      "competition Clarifai image recognition label: competition\n",
      "creativity Clarifai image recognition label: creativity\n",
      "dark Clarifai image recognition label: dark\n",
      "daylight Clarifai image recognition label: daylight\n",
      "desktop Clarifai image recognition label: desktop\n",
      "empty Clarifai image recognition label: empty\n",
      "equipment Clarifai image recognition label: equipment\n",
      "face Clarifai image recognition label: face\n",
      "fashion Clarifai image recognition label: fashion\n",
      "furniture Clarifai image recognition label: furniture\n",
      "girl Clarifai image recognition label: girl\n",
      "hand Clarifai image recognition label: hand\n",
      "horizontal Clarifai image recognition label: horizontal\n",
      "illustration Clarifai image recognition label: illustration\n",
      "image Clarifai image recognition label: image\n",
      "landscape Clarifai image recognition label: landscape\n",
      "light Clarifai image recognition label: light\n",
      "man Clarifai image recognition label: man\n",
      "military Clarifai image recognition label: military\n",
      "music Clarifai image recognition label: music\n",
      "old Clarifai image recognition label: old\n",
      "one Clarifai image recognition label: one\n",
      "outdoors Clarifai image recognition label: outdoors\n",
      "brightness Average luminosity of the pixels\n",
      "vibrance Variance of color channels\n",
      "sharpness Degree of blur/sharpness of the image\n",
      "portrait Clarifai image recognition label: portrait\n",
      "recreation Clarifai image recognition label: recreation\n",
      "retro Clarifai image recognition label: retro\n",
      "road Clarifai image recognition label: road\n",
      "room Clarifai image recognition label: room\n",
      "simplicity Clarifai image recognition label: simplicity\n",
      "sky Clarifai image recognition label: sky\n",
      "street Clarifai image recognition label: street\n",
      "summer Clarifai image recognition label: summer\n",
      "sunset Clarifai image recognition label: sunset\n",
      "technology Clarifai image recognition label: technology\n",
      "text Clarifai image recognition label: text\n",
      "travel Clarifai image recognition label: travel\n",
      "two Clarifai image recognition label: two\n",
      "vehicle Clarifai image recognition label: vehicle\n",
      "vertical Clarifai image recognition label: vertical\n",
      "water Clarifai image recognition label: water\n",
      "wear Clarifai image recognition label: wear\n",
      "wild Clarifai image recognition label: wild\n",
      "wildlife Clarifai image recognition label: wildlife\n",
      "woman Clarifai image recognition label: woman\n",
      "wood Clarifai image recognition label: wood\n",
      "writing Clarifai image recognition label: writing\n",
      "as-Music AudioSet Level 1 label: Music\n",
      "as-Animal AudioSet Level 1 label: Animal\n",
      "as-Whistling AudioSet Level 2 label: Whistling\n",
      "as-Vehicle AudioSet Level 2 label: Vehicle\n",
      "as-Wild animals AudioSet Level 2 label: Wild animals\n",
      "as-Thunderstorm AudioSet Level 2 label: Thunderstorm\n",
      "as-Noise AudioSet Level 2 label: Noise\n",
      "as-Fire AudioSet Level 2 label: Fire\n",
      "as-Water AudioSet Level 2 label: Water\n",
      "as-Wind AudioSet Level 2 label: Wind\n",
      "as-Glass AudioSet Level 2 label: Glass\n",
      "as-Wood AudioSet Level 2 label: Wood\n",
      "as-Silence AudioSet Level 2 label: Silence\n",
      "as-Mechanisms AudioSet Level 2 label: Mechanisms\n",
      "as-Alarm AudioSet Level 2 label: Alarm\n",
      "as-Hands AudioSet Level 2 label: Hands\n",
      "as-Tools AudioSet Level 2 label: Tools\n",
      "speech Speech (binarized, on or off)\n",
      "tool Clarifai image recognition label: tool\n",
      "rms Root mean square (RMS) energy from audio\n",
      "tonal_centroid_0 Tonal centroid 0\n",
      "face_count None\n",
      "log_mean_time_since None\n",
      "first_time_face None\n",
      "any_faces None\n",
      "log_max_time_since None\n",
      "tonal_centroid_2 Tonal centroid 2\n",
      "tonal_centroid_3 Tonal centroid 3\n",
      "text_length Number of letters in each spoken word.\n",
      "BERTLM_pre_25_entropy Entropy of BERT LM encoding vectors.\n",
      "tonal_centroid_4 Tonal centroid 4\n",
      "tonal_centroid_5 Tonal centroid 5\n",
      "chroma_cqt_0 Constant-q chromogram bin 0\n",
      "chroma_cqt_1 Constant-q chromogram bin 1\n",
      "chroma_cqt_2 Constant-q chromogram bin 2\n",
      "chroma_cqt_3 Constant-q chromogram bin 3\n",
      "chroma_cqt_5 Constant-q chromogram bin 5\n",
      "chroma_cqt_6 Constant-q chromogram bin 6\n",
      "chroma_cqt_7 Constant-q chromogram bin 7\n",
      "chroma_cqt_8 Constant-q chromogram bin 8\n",
      "chroma_cqt_9 Constant-q chromogram bin 9\n",
      "chroma_cqt_11 Constant-q chromogram bin 11\n",
      "as-Speech AudioSet Level 1 label: Speech\n",
      "mel_1 Melspectrogram bin 1\n",
      "mel_2 Melspectrogram bin 2\n",
      "mel_4 Melspectrogram bin 4\n",
      "mel_5 Melspectrogram bin 5\n",
      "mel_6 Melspectrogram bin 6\n",
      "mel_8 Melspectrogram bin 8\n",
      "mel_9 Melspectrogram bin 9\n",
      "mel_12 Melspectrogram bin 12\n",
      "mel_13 Melspectrogram bin 13\n",
      "mel_14 Melspectrogram bin 14\n",
      "mel_15 Melspectrogram bin 15\n",
      "mel_17 Melspectrogram bin 17\n",
      "mel_18 Melspectrogram bin 18\n",
      "mel_19 Melspectrogram bin 19\n",
      "mel_21 Melspectrogram bin 21\n",
      "mel_22 Melspectrogram bin 22\n",
      "mel_23 Melspectrogram bin 23\n",
      "mel_25 Melspectrogram bin 25\n",
      "mel_26 Melspectrogram bin 26\n",
      "mel_27 Melspectrogram bin 27\n",
      "mel_29 Melspectrogram bin 29\n",
      "mel_30 Melspectrogram bin 30\n",
      "mel_31 Melspectrogram bin 31\n",
      "mel_33 Melspectrogram bin 33\n",
      "mel_34 Melspectrogram bin 34\n",
      "mel_35 Melspectrogram bin 35\n",
      "mel_37 Melspectrogram bin 37\n",
      "mel_38 Melspectrogram bin 38\n",
      "mel_39 Melspectrogram bin 39\n",
      "mel_41 Melspectrogram bin 41\n",
      "mel_42 Melspectrogram bin 42\n",
      "mel_43 Melspectrogram bin 43\n",
      "mel_44 Melspectrogram bin 44\n",
      "mel_46 Melspectrogram bin 46\n",
      "mel_47 Melspectrogram bin 47\n",
      "mfcc_1 Mel Frequency Ceptral Coefficients, 1\n",
      "mfcc_2 Mel Frequency Ceptral Coefficients, 2\n",
      "mfcc_4 Mel Frequency Ceptral Coefficients, 4\n",
      "mfcc_5 Mel Frequency Ceptral Coefficients, 5\n",
      "mfcc_6 Mel Frequency Ceptral Coefficients, 6\n",
      "mfcc_7 Mel Frequency Ceptral Coefficients, 7\n",
      "mfcc_8 Mel Frequency Ceptral Coefficients, 8\n",
      "mfcc_10 Mel Frequency Ceptral Coefficients, 10\n",
      "mfcc_11 Mel Frequency Ceptral Coefficients, 11\n",
      "mfcc_12 Mel Frequency Ceptral Coefficients, 12\n",
      "mfcc_13 Mel Frequency Ceptral Coefficients, 13\n",
      "mfcc_15 Mel Frequency Ceptral Coefficients, 15\n",
      "mfcc_16 Mel Frequency Ceptral Coefficients, 16\n",
      "mfcc_17 Mel Frequency Ceptral Coefficients, 17\n",
      "mfcc_18 Mel Frequency Ceptral Coefficients, 18\n",
      "alphabet Clarifai image recognition label: alphabet\n",
      "building Clarifai image recognition label: building\n",
      "color Clarifai image recognition label: color\n",
      "design Clarifai image recognition label: design\n",
      "family Clarifai image recognition label: family\n",
      "home Clarifai image recognition label: home\n",
      "indoors Clarifai image recognition label: indoors\n",
      "nature Clarifai image recognition label: nature\n",
      "pattern Clarifai image recognition label: pattern\n",
      "shot_change Transitions between scene cuts in video\n",
      "as-Explosion AudioSet Level 2 label: Explosion\n",
      "as-Engine AudioSet Level 2 label: Engine\n",
      "as-Liquid AudioSet Level 2 label: Liquid\n",
      "as-Musical instrument AudioSet Level 2 label: Musical instrument\n",
      "people Clarifai image recognition label: people\n",
      "tonal_centroid_1 Tonal centroid 1\n",
      "log_mean_face_time_cum None\n",
      "log_max_face_time_cum None\n",
      "spectral_centroid Spectral centroids from audio\n",
      "chroma_cqt_4 Constant-q chromogram bin 4\n",
      "chroma_cqt_10 Constant-q chromogram bin 10\n",
      "mel_0 Melspectrogram bin 0\n",
      "mel_3 Melspectrogram bin 3\n",
      "mel_7 Melspectrogram bin 7\n",
      "mel_11 Melspectrogram bin 11\n",
      "mel_16 Melspectrogram bin 16\n",
      "mel_20 Melspectrogram bin 20\n",
      "mel_24 Melspectrogram bin 24\n",
      "mel_28 Melspectrogram bin 28\n",
      "mel_32 Melspectrogram bin 32\n",
      "mel_36 Melspectrogram bin 36\n",
      "mel_40 Melspectrogram bin 40\n",
      "mel_45 Melspectrogram bin 45\n",
      "mfcc_0 Mel Frequency Ceptral Coefficients, 0\n",
      "mfcc_3 Mel Frequency Ceptral Coefficients, 3\n",
      "mfcc_9 Mel Frequency Ceptral Coefficients, 9\n",
      "mfcc_14 Mel Frequency Ceptral Coefficients, 14\n",
      "mfcc_19 Mel Frequency Ceptral Coefficients, 19\n"
     ]
    }
   ],
   "source": [
    "budapest_predictors=api.predictors.get(run_id=run_id)\n",
    "for i in budapest_predictors:\n",
    "    if not i['source'] == 'fmriprep':\n",
    "        print(i['name'],i['description'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suspended-search",
   "metadata": {},
   "source": [
    "#### get ids and names of predictors?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "positive-saturn",
   "metadata": {},
   "outputs": [],
   "source": [
    "budapest_predictor_ids = []\n",
    "budapest_predictor_names = []\n",
    "for i in budapest_predictors:\n",
    "    if not i['source'] == 'fmriprep':\n",
    "        budapest_predictor_ids.append(i['id'])\n",
    "        budapest_predictor_names.append(i['name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extensive-pathology",
   "metadata": {},
   "source": [
    "#### how many values are in each predictor??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "historical-journalism",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_lengths = []\n",
    "for i in budapest_predictor_ids:\n",
    "    predictor_lengths.append(\n",
    "        len(api.predictor_events.get(predictor_id=i, run_id=run_id))\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "conservative-tokyo",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 5765 1529.017543859649\n"
     ]
    }
   ],
   "source": [
    "predictor_lengths=np.array(predictor_lengths)\n",
    "print(predictor_lengths.min(), predictor_lengths.max(), predictor_lengths.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "micro-seminar",
   "metadata": {},
   "outputs": [],
   "source": [
    "an_event=api.predictor_events.get(predictor_id=budapest_predictor_ids[37],run_id=run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "portable-equation",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['onset','duration','value'])\n",
    "for i in an_event:\n",
    "    df = df.append({'onset': i['onset'], 'duration': i['duration'], 'value': i['value']}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "standard-collection",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>onset</th>\n",
       "      <th>duration</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.016625665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.016165715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.02323487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.011340556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0072452063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>583.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.46360168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>584.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.39699513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>585.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.3872752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>586.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.65442675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>587.0</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.06373329</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>578 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     onset  duration         value\n",
       "0     10.0      1.00   0.016625665\n",
       "1     11.0      1.00   0.016165715\n",
       "2     12.0      1.00    0.02323487\n",
       "3     13.0      1.00   0.011340556\n",
       "4     14.0      1.00  0.0072452063\n",
       "..     ...       ...           ...\n",
       "573  583.0      1.00    0.46360168\n",
       "574  584.0      1.00    0.39699513\n",
       "575  585.0      1.00     0.3872752\n",
       "576  586.0      1.00    0.65442675\n",
       "577  587.0      0.42    0.06373329\n",
       "\n",
       "[578 rows x 3 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tight-liberty",
   "metadata": {},
   "source": [
    "### given an event... convert it from duration onset value to timeseries\n",
    "- sort it (the dicts are out of order)\n",
    "- convert to timeseries\n",
    "- resample it (eg some are variable mean 150 hz?? others are regular 0.6 hz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blond-warren",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
